{
  "id": "openvino_helloworld",
  "version": "1.0",
  "name": "Workflow Openvino example",
  "description": "The openvino hello world example running on serveless workflow",
  "start": "Imports",
  "functions": [
    {
      "name": "python",
      "type": "custom",
      "operation": "script:python"
    }
  ],
  "states": [
    {
      "name": "Imports",
      "type": "operation",
      "actions": [
        {
          "functionRef": {
            "refName": "python",
            "arguments": {
              "script": "from pathlib import Path\nimport sys\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom openvino.runtime import Core\nsys.path.append('./utils')\nfrom notebook_utils import download_file"
            }
          }
        }
      ],
      "transition": "Download the model"
    },
    {
      "name": "Download the model",
      "type": "operation",
      "actions" : [
        {
          "functionRef": {
            "name":"Model names",
            "refName": "python",
            "arguments": {
              "script": "base_artifacts_dir = Path('./model').expanduser()\nmodel_name = 'v3-small_224_1.0_float'\nmodel_xml_name = f'{model_name}.xml'\nmodel_bin_name = f'{model_name}.bin'\nmodel_xml_path = base_artifacts_dir / model_xml_name\nbase_url = 'https://storage.openvinotoolkit.org/repositories/openvino_notebooks/models/mobelinet-v3-tf/FP32/'"
            }
          }
        },
        {
          "functionRef": {
            "name":"Download model",
            "refName": "python",
            "arguments": {
              "script": "if not model_xml_path.exists():\n\tdownload_file(base_url + model_xml_name, model_xml_name, base_artifacts_dir)\n\tdownload_file(base_url + model_bin_name, model_bin_name, base_artifacts_dir)\nelse:\n\tprint(f'{model_name} already downloaded to {base_artifacts_dir}')"
            }
          }
        }],
        "transition" : "Load model"
    },
    {
      "name" : "Load model",
      "type": "operation",
      "actions": [
        {
          "functionRef": {
            "refName": "python",
            "arguments": {
              "script": "ie = Core()\nmodel = ie.read_model(model=model_xml_path)\ncompiled_model = ie.compile_model(model=model, device_name='CPU')\noutput_layer = compiled_model.output(0)"
            }
          }
        } 
        ],
        "transition": "Load image"
    },
    {
        "name": "Load image",
        "type": "operation",
        "actions": [
          {
            "functionRef": {
              "refName": "python",
              "arguments": {
                "script": "image = cv2.cvtColor(cv2.imread(filename=fileName), code=cv2.COLOR_BGR2RGB)\ninput_image = cv2.resize(src=image, dsize=(224, 224))\ninput_image = np.expand_dims(input_image, 0)\n",
                "fileName" : ".fileName"
              }
            }
          }
        ],
        "transition": "Do inference"        
    },{
        "name": "Do inference",
        "type": "operation",
        "actions": [
        {
          "functionRef": {
            "name":"Compile model",
            "refName": "python",
            "arguments": {
              "script": "result_infer = compiled_model([input_image])[output_layer]\nresult_index = np.argmax(result_infer)"
            }
          }
        },
        {
          "functionRef": {
            "name":"Provide result",
            "refName": "python",
            "arguments": {
              "script": "imagenet_classes = open('data/imagenet_2012.txt').read().splitlines()\nimagenet_classes = ['background'] + imagenet_classes\n"
            }
          }
        }],
        "stateDataFilter" : {
        "output" : "{group:$WORKFLOW.python.imagenet_classes[$WORKFLOW.python.result_index]}"
        },
        "end": true
      }
  ]
}
